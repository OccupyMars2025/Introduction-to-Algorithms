To address the problems presented in the images for a randomly built binary search tree, let's go through each part step-by-step.

### Problem 12-3: Average Node Depth in a Randomly Built Binary Search Tree

### Part (a)
**Statement:**
Argue that the average depth of a node in \( T \) is \(\frac{1}{n} P(T)\).

Given that we need to show that the expected value of \( P(T) \) is \( \Theta(n \log n) \).

#### Solution:
To show that the expected value of \( P(T) \) is \( O(n \log n) \), we will use the recurrence relation and properties of binary search trees.

1. **Total Path Length \( P(T) \)**:
   The total path length \( P(T) \) is the sum of the depths of all nodes in the tree. If \( T \) has \( n \) nodes, and \( T_L \) and \( T_R \) are the left and right subtrees respectively, we can express \( P(T) \) as:

   \[
   P(T) = P(T_L) + P(T_R) + n - 1
   \]

   Yes, the derivation of the recurrence relation for the expected total path length \( P(n) \) in a randomly built binary search tree leverages the Law of Total Expectation. Let's break down how this applies.

### Law of Total Expectation

The Law of Total Expectation states that if \( Y \) is a random variable and \( X \) is another random variable upon which \( Y \) depends, then:

\[
E[Y] = E[E[Y|X]]
\]

### Application to Binary Search Trees

In the context of binary search trees, let:
- \( T \) be a randomly built binary search tree with \( n \) nodes.
- \( P(T) \) be the total path length of tree \( T \).

The expected total path length \( P(n) \) for a tree with \( n \) nodes can be computed by considering all possible configurations of the tree.

1. **Choice of Root**:
   - Each node in the tree can be the root with equal probability \( \frac{1}{n} \).

2. **Subtrees**:
   - Given a particular node \( i \) is chosen as the root, the size of the left subtree \( T_L \) can be \( k \) and the size of the right subtree \( T_R \) can be \( n - k - 1 \) (since one node is the root).

3. **Conditional Expectation**:
   - The total path length \( P(n) \) can be expressed as the sum of the total path lengths of the left and right subtrees plus the depth increment due to the root.

Thus, the expected total path length \( P(n) \) can be written as:

\[
P(n) = E[P(T)] = \frac{1}{n} \sum_{i=0}^{n-1} E[P(T) \mid \text{root is node } i]
\]

Given that each node is equally likely to be the root, we can sum over all possible roots:

\[
P(n) = \frac{1}{n} \sum_{i=0}^{n-1} \left( P(i) + P(n-i-1) + n - 1 \right)
\]



1. **Recurrence Relation**:
   For a tree with \( n \) nodes, the recurrence relation is:

   \[
   P(n) = \frac{1}{n} \sum_{i=0}^{n-1} (P(i) + P(n-i-1) + n - 1)
   \]

2. **Simplifying the Recurrence**:
   By symmetry and the linearity of expectation, we can rewrite the sum:

   \[
   \sum_{i=0}^{n-1} (P(i) + P(n-i-1)) = 2 \sum_{i=1}^{n-1} P(i)
   \]

   Thus, we get:

   \[
   P(n) = \frac{1}{n} \left(2 \sum_{i=1}^{n-1} P(i) + n(n-1)\right)
   \]

   Simplifying further:

   \[
   P(n) = \frac{2}{n} \sum_{i=1}^{n-1} P(i) + (n-1)
   \]

3. **Converting the Recurrence**:
   To solve this recurrence, we use the technique of guessing and verifying. Suppose:

   \[
   P(n) = c n \log n
   \]

   For some constant \( c \). Substitute \( P(n) = c n \log n \) into the recurrence:

   \[
   c n \log n = \frac{2}{n} \sum_{i=1}^{n-1} (c i \log i) + (n-1)
   \]

   This simplifies to:

   \[
   c n \log n = \frac{2c}{n} \sum_{i=1}^{n-1} (i \log i) + (n-1)
   \]

4. **Approximating the Sum**:
   We need to approximate the sum \( \sum_{i=1}^{n-1} i \log i \). Using integration for approximation:

   \[
   \sum_{i=1}^{n-1} i \log i \approx \int_{1}^{n} x \log x \, dx
   \]

   Solving the integral:

   \[
   \int x \log x \, dx = \frac{x^2 \log x}{2} - \frac{x^2}{4} + C
   \]

   Evaluate from 1 to \( n \):

   \[
   \left[ \frac{x^2 \log x}{2} - \frac{x^2}{4} \right]_1^n = \frac{n^2 \log n}{2} - \frac{n^2}{4} - \left( \frac{1 \log 1}{2} - \frac{1}{4} \right)
   \]

   Simplifying:

   \[
   \sum_{i=1}^{n-1} i \log i \approx \frac{n^2 \log n}{2} - \frac{n^2}{4}
   \]

5. **Substituting Back**:
   Substitute this back into the recurrence:

   \[
   c n \log n = \frac{2c}{n} \left(\frac{n^2 \log n}{2} - \frac{n^2}{4}\right) + (n-1)
   \]

   Simplify the terms:

   \[
   c n \log n = c n \log n - \frac{c n}{2} + (n-1)
   \]

   The dominating term on both sides is \( c n \log n \). The remaining terms (which include \(\frac{c n}{2}\) and \((n-1)\)) are lower order terms compared to \( c n \log n \).

Thus, \( P(n) = O(n \log n) \), showing that the total path length of a randomly built binary search tree is \( O(n \log n) \). This implies that the average depth of a node in the tree is \( O(\log n) \).

#### Part (b)
**Statement:**
Let \( T_L \) and \( T_R \) denote the left and right subtrees of tree \( T \), respectively. Argue that if \( T \) has \( n \) nodes, then:

\[ P(T) = P(T_L) + P(T_R) + n - 1 \]

**Solution:**
In a binary search tree, every node except the root has a parent. Therefore, the total path length of the tree can be computed by summing the path lengths of the left and right subtrees and adding the depth contribution from the root.

For a tree \( T \) with \( n \) nodes:
- \( P(T_L) \) is the total path length of the left subtree.
- \( P(T_R) \) is the total path length of the right subtree.

Every node in \( T_L \) and \( T_R \) has its depth incremented by 1 when considering the depth in \( T \) due to the root of \( T \). Hence, we add \( n-1 \) to account for this increment:

\[ P(T) = P(T_L) + P(T_R) + (n - 1) \]

#### Part (c)
**Statement:**
Let \( P(n) \) denote the expected total path length of a randomly built binary search tree with \( n \) nodes. Show that:

\[ P(n) = \frac{1}{n} \sum_{i=0}^{n-1} (P(i) + P(n-i-1) + n - 1) \]

**Solution:**
The expected total path length \( P(n) \) of a randomly built binary search tree with \( n \) nodes can be computed as follows:

\[ P(n) = \frac{1}{n} \sum_{i=0}^{n-1} (P(i) + P(n-i-1) + n - 1) \]

This formula accounts for all possible ways of dividing the \( n \) nodes into left and right subtrees. The term \( P(i) + P(n-i-1) \) accounts for the expected path lengths of the left and right subtrees. The term \( n - 1 \) accounts for the depth increment contributed by the root node.

#### Part (d)
**Statement:**
Show how to rewrite \( P(n) \) as:

\[ P(n) = \frac{2}{n} \sum_{k=1}^{n-1} P(k) + \Theta(n) \]

**Solution:**
Starting from the equation in part (c):

\[ P(n) = \frac{1}{n} \sum_{i=0}^{n-1} (P(i) + P(n-i-1) + n - 1) \]

We can rewrite it by recognizing the symmetry and the fact that:

\[ \sum_{i=0}^{n-1} (P(i) + P(n-i-1)) = 2 \sum_{k=1}^{n-1} P(k) \]

Thus, we have:

\[ P(n) = \frac{1}{n} \left( 2 \sum_{k=1}^{n-1} P(k) + n(n-1) \right) \]

Simplifying further:

\[ P(n) = \frac{2}{n} \sum_{k=1}^{n-1} P(k) + (n-1) \]

So:

\[ P(n) = \frac{2}{n} \sum_{k=1}^{n-1} P(k) + \Theta(n) \]

#### Part (e)
**Statement:**
Recalling the alternative analysis of the randomized version of quicksort given in Problem 7-3, conclude that \( P(n) = O(n \log n) \).

**Solution:**
The analysis of randomized quicksort shows that the expected running time is \( O(n \log n) \). Since the total path length \( P(n) \) of a randomly built binary search tree follows the same recurrence relation as the expected running time of randomized quicksort, we can conclude that:

\[ P(n) = O(n \log n) \]

#### Part (f)
**Statement:**
Describe an implementation of quicksort in which the comparisons to sort a set of elements are exactly the same as the comparisons to insert the elements into a binary search tree.

**Solution:**
To ensure the comparisons in quicksort are the same as in inserting elements into a binary search tree, we can modify the quicksort algorithm as follows:

1. Choose the first element as the pivot.
2. Partition the remaining elements into two groups: those less than the pivot (left subtree) and those greater than or equal to the pivot (right subtree).
3. Recursively apply the same process to the left and right groups.

This mirrors the insertion process in a binary search tree, where each element is compared to the pivot to determine its position.

### Quicksort Implementation

```cpp
#include <vector>
#include <iostream>
#include <algorithm>

void quicksort(std::vector<int>& arr, int left, int right) {
    if (left >= right) {
        return;
    }

    int pivot = arr[left];
    int i = left + 1;
    int j = right;

    while (i <= j) {
        while (i <= j && arr[i] < pivot) {
            i++;
        }
        while (i <= j && arr[j] >= pivot) {
            j--;
        }
        if (i < j) {
            std::swap(arr[i], arr[j]);
        }
    }

    std::swap(arr[left], arr[j]);

    quicksort(arr, left, j - 1);
    quicksort(arr, j + 1, right);
}

int main() {
    std::vector<int> arr = {3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5};
    quicksort(arr, 0, arr.size() - 1);
    for (int num : arr) {
        std::cout << num << " ";
    }
    return 0;
}
```

In this quicksort implementation:
- The first element is chosen as the pivot.
- Elements are partitioned into left and right subgroups based on comparisons to the pivot.
- This partitioning process mirrors the way elements are inserted into a binary search tree.